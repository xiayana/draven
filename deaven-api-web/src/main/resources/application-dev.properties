# kafka
kafka.consumer.servers=192.168.3.104:9092
#最早未被消费的offset,设置为earliest;当前的latest
kafka.consumer.auto.offset.reset=latest
kafka.consumer.group.id=deaven-consumer
#批量消费一次最大拉取的数据量
kafka.consumer.max.poll.records=2000
#是否开启自动提交
kafka.consumer.enable.auto.commit=true
#自动提交的间隔时间
kafka.consumer.auto.commit.interval=1000
#连接超时时间
kafka.consumer.session.timeout=300000
#手动提交设置与poll的心跳数
kafka.consumer.max.poll.interval=30000
#是否开启批量消费，true表示批量消费
kafka.listener.batch.listener=true
#设置消费的线程数
kafka.consumer.concurrency=5
kafka.listener.poll.timeout=5000
kafka.consumer.topic=test_topic
kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://localhost:3306/test2
spring.datasource.username=root
spring.datasource.password=root
spring.datasource.max-idle=10
spring.datasource.max-wait=10000
spring.datasource.min-idle=5
spring.datasource.initial-size=5

#mybatis
mybatis.typeAliasesPackage: com.example.demo.entity
mybatis.mapperLocations: classpath:mapper/*.xml
#configLocation: classpath:/mybatis-config.xml
dsl.engine.server=localhost:8099